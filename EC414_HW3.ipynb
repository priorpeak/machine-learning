{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "EC414_HW3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlrLhVfVEBgC"
      },
      "source": [
        "# Homework 3: Optimization, KNN and Decision Trees\n",
        "by Rachel Manzelli and Brian Kulis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyW6bcPOEBgE"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAu-evguEBgF"
      },
      "source": [
        "To run and solve this assignment, you must have access to a working Jupyter Notebook installation. We recommend Google Colab. If you are already familiar with Jupyter and have your own installation, you may use it; however, you will have to tweak Colab-specific commands we've entered here (for example, file uploads).\n",
        "\n",
        "To use Google Colab:\n",
        "\n",
        "1. Download this `ipynb` file.\n",
        "2. Navigate to https://colab.research.google.com/ and select `Upload` in the pop-up window.\n",
        "3. Upload this file. It will then open in Colab.\n",
        "\n",
        "The below statements assume that you have already followed these instructions. If you need help with Python syntax, NumPy, or Matplotlib, you might find Week 1 discussion material useful.\n",
        "\n",
        "To run code in a cell or to render Markdown+LaTeX press Ctrl+Enter or \"`Run`\" button above. To edit any code or text cell, double-click on its content. Put your solution into boxes marked with **`[double click here to add a solution]`** and press Ctrl+Enter to render text. You can add cells via `+` sign at the top left corner.\n",
        "\n",
        "**Submission instructions**: please upload your completed solution file as well as a scan of any handwritten answers to Gradescope by **February 24th at midnight**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtfCnBdvEBgF"
      },
      "source": [
        "### 1. Maximum Likelihood without a Closed-Form Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnjmfbPrEBgG"
      },
      "source": [
        "Assume that we are given $n$ IID samples ${x_1,...x_n}$ from the following $P(X|\\theta)$:\n",
        "\n",
        "$$P(X|\\theta) = \\frac{1}{\\pi}\\bigg [\\frac{1}{(x-\\theta)^2+1}\\bigg ]$$\n",
        "\n",
        "#### 1.a. Try to compute the MLE via maximizing the log-likelihood function directly, and briefly explain why this won't work."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tk9IzrPEBgG"
      },
      "source": [
        "(See bottom)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mutaA-INEBgG"
      },
      "source": [
        "#### 1.b. Convert the objective (log-likelihood) function into a cost function, $J(\\theta)$, that we can minimize using gradient descent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDFqJhmSEBgH"
      },
      "source": [
        "(See bottom)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYQnbVZnEBgH"
      },
      "source": [
        "#### 1.c. Compute the gradient descent update rule, where $\\theta_{n+1}=\\theta_n - \\alpha\\frac{d}{d\\theta_n}J(\\theta_n)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3AGfZDIEBgH"
      },
      "source": [
        "(See bottom)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOtUUJeREBgH"
      },
      "source": [
        "#### 1.d. Write the pseudocode for gradient descent with this update rule."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYcRigipEBgH"
      },
      "source": [
        "(See bottom)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Igc3EWwEBgI"
      },
      "source": [
        "#### 1.e. (Bonus) Compute the stochastic gradient descent (SGD) update rule, and write pseudocode for SGD with this update rule. (Assume a mini-batch size of 1.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUNKxhkXEBgI"
      },
      "source": [
        "(See bottom)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGlRpwK-EBgI"
      },
      "source": [
        "### 2. Decision Trees\n",
        "\n",
        "The following dataset contains information about different weather attributes, along with whether the golf team decided to play. Each row represents the characteristics of one day.\n",
        "\n",
        "\n",
        "| Temp        | Humidity    | Wind        | Play?       |\n",
        "| ----------- | ----------- | ----------- | ----------- |\n",
        "| hot         | normal      | strong      | no          |\n",
        "| mild        | high        | strong      | yes         |\n",
        "| hot         | normal      | strong      | no          |\n",
        "| hot         | normal      | weak        | yes         |\n",
        "| mild        | normal      | strong      | yes         |\n",
        "\n",
        "\n",
        "We will construct a decision tree that predicts whether or not the current weather attributes are appropriate for playing golf."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiMzkoNyEBgI"
      },
      "source": [
        "#### 2.a. Choose a root node.\n",
        "Follow the method of using information gain to choose a root node for our decision tree, as described in class (and posted in the slides on Blackboard)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfnVZPewEBgI"
      },
      "source": [
        "(See bottom)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRJSQ1lKEBgJ"
      },
      "source": [
        "#### 2.b. Complete the tree.\n",
        "Repeat the method of using information gain to split on another feature, as described in class (and posted in the slides on Blackboard)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9lNw9mCEBgJ"
      },
      "source": [
        "(See bottom)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HG0HNMkOEBgJ"
      },
      "source": [
        "### 3. K-Nearest Neighbors on NIST\n",
        "\n",
        "We're going to build a K-nearest neighbors classifier from scratch, including validating for the best K, and test it out on NIST, a handwritten digits dataset.\n",
        "\n",
        "The 64 features of this dataset are the values of each pixel in the 8x8 image grid of one handwritten digit, where the digits are written in white (pixel value 255) and the surrounding space is black (pixel value 0). Each sample represents one image.\n",
        "\n",
        "#### First, install the latest release of `sklearn`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fx4MHQquEBgK",
        "outputId": "71c0eb67-aa35-47ca-b6f4-ed381802b9f6"
      },
      "source": [
        "# These datasets require the latest release of sklearn (0.24.1).\n",
        "# We are going to uninstall the default Colab version (if you are using Colab) or your current version, and install version 0.24.1.\n",
        "# AFTER RUNNING THIS CELL, YOU MAY NEED TO RESTART THE RUNTIME. GO TO Runtime/Kernel -> Restart Runtime to do this. \n",
        "# (Or, in Colab, hit the RESTART RUNTIME button at the bottom if there is an error message when you run this cell.)\n",
        "# You only need to do this once, but if the Colab runtime disconnects, you will need to do it again!\n",
        "\n",
        "!pip uninstall scikit-learn -y\n",
        "!pip install scikit-learn==0.24.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling scikit-learn-0.24.1:\n",
            "  Successfully uninstalled scikit-learn-0.24.1\n",
            "Collecting scikit-learn==0.24.1\n",
            "  Using cached https://files.pythonhosted.org/packages/e2/4c/6111b9a325f29527d7f262e2ee8c730d354b47a728d955e186dacad57a0d/scikit_learn-0.24.1-cp36-cp36m-manylinux2010_x86_64.whl\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.24.1) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.24.1) (1.19.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.24.1) (2.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.24.1) (1.0.0)\n",
            "Installing collected packages: scikit-learn\n",
            "Successfully installed scikit-learn-0.24.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PA9Zcj9EEBgK"
      },
      "source": [
        "#### Verify we're using the correct version. (If it is not 0.24.1, restart the runtime, or try installing again.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idDnb1hyEBgK",
        "outputId": "8920841e-d93b-4bab-9fa4-9d20cf4c6981"
      },
      "source": [
        "import sklearn\n",
        "print(sklearn.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.24.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPYZ66riEBgK"
      },
      "source": [
        "#### Import the data and take a look at some samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "GxHiRN12EBgL",
        "outputId": "b062654c-5666-4c25-b9e2-b89261ff7f0a"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_digits\n",
        "\n",
        "# Import the data into a pandas dataframe\n",
        "nist = load_digits()\n",
        "nist_df = pd.DataFrame(nist.data, columns = nist.feature_names)\n",
        "\n",
        "# Split data into features and labels\n",
        "X = nist.data\n",
        "y = nist.target\n",
        "\n",
        "# View the raw data\n",
        "nist_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pixel_0_0</th>\n",
              "      <th>pixel_0_1</th>\n",
              "      <th>pixel_0_2</th>\n",
              "      <th>pixel_0_3</th>\n",
              "      <th>pixel_0_4</th>\n",
              "      <th>pixel_0_5</th>\n",
              "      <th>pixel_0_6</th>\n",
              "      <th>pixel_0_7</th>\n",
              "      <th>pixel_1_0</th>\n",
              "      <th>pixel_1_1</th>\n",
              "      <th>pixel_1_2</th>\n",
              "      <th>pixel_1_3</th>\n",
              "      <th>pixel_1_4</th>\n",
              "      <th>pixel_1_5</th>\n",
              "      <th>pixel_1_6</th>\n",
              "      <th>pixel_1_7</th>\n",
              "      <th>pixel_2_0</th>\n",
              "      <th>pixel_2_1</th>\n",
              "      <th>pixel_2_2</th>\n",
              "      <th>pixel_2_3</th>\n",
              "      <th>pixel_2_4</th>\n",
              "      <th>pixel_2_5</th>\n",
              "      <th>pixel_2_6</th>\n",
              "      <th>pixel_2_7</th>\n",
              "      <th>pixel_3_0</th>\n",
              "      <th>pixel_3_1</th>\n",
              "      <th>pixel_3_2</th>\n",
              "      <th>pixel_3_3</th>\n",
              "      <th>pixel_3_4</th>\n",
              "      <th>pixel_3_5</th>\n",
              "      <th>pixel_3_6</th>\n",
              "      <th>pixel_3_7</th>\n",
              "      <th>pixel_4_0</th>\n",
              "      <th>pixel_4_1</th>\n",
              "      <th>pixel_4_2</th>\n",
              "      <th>pixel_4_3</th>\n",
              "      <th>pixel_4_4</th>\n",
              "      <th>pixel_4_5</th>\n",
              "      <th>pixel_4_6</th>\n",
              "      <th>pixel_4_7</th>\n",
              "      <th>pixel_5_0</th>\n",
              "      <th>pixel_5_1</th>\n",
              "      <th>pixel_5_2</th>\n",
              "      <th>pixel_5_3</th>\n",
              "      <th>pixel_5_4</th>\n",
              "      <th>pixel_5_5</th>\n",
              "      <th>pixel_5_6</th>\n",
              "      <th>pixel_5_7</th>\n",
              "      <th>pixel_6_0</th>\n",
              "      <th>pixel_6_1</th>\n",
              "      <th>pixel_6_2</th>\n",
              "      <th>pixel_6_3</th>\n",
              "      <th>pixel_6_4</th>\n",
              "      <th>pixel_6_5</th>\n",
              "      <th>pixel_6_6</th>\n",
              "      <th>pixel_6_7</th>\n",
              "      <th>pixel_7_0</th>\n",
              "      <th>pixel_7_1</th>\n",
              "      <th>pixel_7_2</th>\n",
              "      <th>pixel_7_3</th>\n",
              "      <th>pixel_7_4</th>\n",
              "      <th>pixel_7_5</th>\n",
              "      <th>pixel_7_6</th>\n",
              "      <th>pixel_7_7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   pixel_0_0  pixel_0_1  pixel_0_2  ...  pixel_7_5  pixel_7_6  pixel_7_7\n",
              "0        0.0        0.0        5.0  ...        0.0        0.0        0.0\n",
              "1        0.0        0.0        0.0  ...       10.0        0.0        0.0\n",
              "2        0.0        0.0        0.0  ...       16.0        9.0        0.0\n",
              "3        0.0        0.0        7.0  ...        9.0        0.0        0.0\n",
              "4        0.0        0.0        0.0  ...        4.0        0.0        0.0\n",
              "\n",
              "[5 rows x 64 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "-hexGGpeEBgM",
        "outputId": "fe52755c-b494-4b3d-ca0a-71d0ed1b2256"
      },
      "source": [
        "# Visualize 10 random samples as 8x8 images\n",
        "from matplotlib import pyplot as plt\n",
        "fig = plt.figure(figsize=(20, 6))  # figure size in inches\n",
        "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
        "\n",
        "for i in range(10):\n",
        "    ax = fig.add_subplot(1, 10, i + 1, xticks=[], yticks=[])\n",
        "    ax.imshow(nist.images[i*4], cmap=plt.cm.binary, interpolation='nearest')\n",
        "    # Label the image with the target value\n",
        "    ax.text(0, 7, str(nist.target[i*4]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x432 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVMsd9gNEBgM"
      },
      "source": [
        "#### 3.a. Split the data into train, test, and validation sets.\n",
        "\n",
        "Use a 60/20/20 split. Make sure to set `random_state=42` to shuffle the dataset in a consistent manner."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7muYeqHEBgN"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "### ADD CODE HERE:\n",
        "# Split the data into training, test, and validation sets, just like we did on HW 2\n",
        "# Make sure to set random_state=42!\n",
        "###\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(X, y, random_state=42, train_size=.8) # -- Code Required --\n",
        "xtrain, xval, ytrain, yval = train_test_split(xtrain, ytrain, random_state=42, train_size=.75) # -- Code Required --"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsvq_4QBEBgN"
      },
      "source": [
        "#### 3.b. Implement a Euclidean distance function.\n",
        "We'll need to calculate the Euclidean distance between points of arbitrary dimensions, which you'll implement by filling in the function below. (*Hint: use [this](https://docs.scipy.org/doc/scipy/reference/spatial.distance.html).*)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPe4GCqxEBgN"
      },
      "source": [
        "from scipy.spatial import distance\n",
        "\n",
        "def euclidean_distance(a, b):\n",
        "    '''\n",
        "    A function that calculates and returns the Euclidean distance between vectors a and b.\n",
        "    '''\n",
        "    \n",
        "    ### ADD CODE HERE: calculate dist, the Euclidean distance between a and b\n",
        "    dist = distance.euclidean(a, b)\n",
        "    return dist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOpYmygCEBgO"
      },
      "source": [
        "#### 3.c. Implement the K-nearest neighbors algorithm.\n",
        "The two functions below make up a skeleton of the KNN algorithm, which you will complete.\n",
        "\n",
        "The first, `compute_neighbors_and_classify()`:\n",
        "1. Computes the neighbors given `k` (the number of neighbors)\n",
        "2. Finds the `k` neighbors with the smallest Euclidean distance to the test point (using `euclidean_distance()` above)\n",
        "3. Returns the most common classification label among those `k` neighbors.\n",
        "\n",
        "The second, `compute_accuracy_on_dataset()`:\n",
        "1. Gets the KNN classification predictions for each test point using `compute_neighbors_and_classify()`.\n",
        "2. Compares the predictions to the real values.\n",
        "3. Returns the accuracy score (how many predictions the model got right divided by total number of samples)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74njd6nSEBgO"
      },
      "source": [
        "from scipy.stats import mode\n",
        "\n",
        "def compute_neighbors_and_classify(X_train, y_train, test_point, k):\n",
        "    '''\n",
        "    A function that computes the k neighbors in X_train closest to one test point, \n",
        "    and returns the classification.\n",
        "    '''\n",
        "    # This is a list to hold all of the distances associated with the points and their labels\n",
        "    distances = []\n",
        "    # Loop over the training points\n",
        "    for i, train_point in enumerate(X_train):\n",
        "        \n",
        "        ### ADD CODE HERE:\n",
        "        # Compute the Euclidean distance `dist` from this training point to the test point\n",
        "        ### \n",
        "        dist = euclidean_distance(train_point, test_point)\n",
        "        # Add the distance, the point, and its label (as a tuple) value to our list\n",
        "        # We use a tuple so we can sort the list later while keeping each neighbor next to its distance\n",
        "        distances.append((dist, train_point, y_train[i]))\n",
        "\n",
        "    # Now that we have all the distances, we need to return the labels with the k smallest distances\n",
        "    # First, sort the list we made by distance\n",
        "    distances = sorted(distances, key=lambda x: x[0])\n",
        "    \n",
        "    # Now, pull out the labels associated with the first k neighbors and add them to a list\n",
        "    k_labels = []\n",
        "    for i in range(k):\n",
        "        k_labels.append(distances[i][2])\n",
        "    \n",
        "    ### ADD CODE HERE:\n",
        "    # Get the label that appears the most times in k_labels using mode(). This is our `classification`.\n",
        "    # If there is no mode, just return any label within the k_labels list.\n",
        "    # Refer to the documentation of mode() to ensure you're getting the correct value:\n",
        "    # https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mode.html\n",
        "    ###\n",
        "\n",
        "    classification = mode(k_labels)[0]\n",
        "    \n",
        "    return classification\n",
        "\n",
        "\n",
        "def compute_accuracy_on_dataset(X_train, y_train, data, labels, k):\n",
        "    '''\n",
        "    A function that computes the accuracy of KNN on a (test) dataset.\n",
        "    '''\n",
        "    accuracy_numerator = 0\n",
        "    # Loop over the dataset we'd like to get the accuracy on\n",
        "    for i, point in enumerate(data):\n",
        "        \n",
        "        ### ADD CODE HERE:\n",
        "        # Compute the neighbors and `classification` for this point with the training data\n",
        "        ###\n",
        "        classification = compute_neighbors_and_classify(X_train, y_train, point, k)\n",
        "\n",
        "        # Compare this classification to the real value in `labels`. \n",
        "        # If the model got it correct, add to a running sum of correct predictions.\n",
        "        accuracy_numerator += 1 if classification == labels[i] else 0\n",
        "    \n",
        "    ### ADD CODE HERE:\n",
        "    # Compute the accuracy: divide the count of correct predictions by the number of samples in the dataset\n",
        "    ###\n",
        "    accuracy = accuracy_numerator / len(data)\n",
        "    \n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rxpv7zx_EBgO"
      },
      "source": [
        "#### 3.d. Run KNN on the NIST dataset with k = 1, and report the accuracy on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vS_u0zeZEBgP",
        "outputId": "8a1be633-f869-4578-a209-27a574ffbc88"
      },
      "source": [
        "### ADD CODE HERE:\n",
        "# Call compute_accuracy_on_dataset() to get the accuracy on the test set with k=1\n",
        "###\n",
        "knn_acc = compute_accuracy_on_dataset(xtrain, ytrain, xtest, ytest, 1)\n",
        "print(\"Accuracy on test set with k = 1:\", knn_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on test set with k = 1: 0.9777777777777777\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgTBfbBzEBgQ"
      },
      "source": [
        "#### 3.d. Find the best value of K by using the validation set.\n",
        "Ideally, we'd like to programmatically find the best value of `k` instead of just guessing what it is. Using the **validation set**, find the best value of `k` by running our KNN algorithm for `k = [1, 2, 3 ... 10]`, and saving the `k` with the best accuracy. \n",
        "\n",
        "Fill in the function below, and then call it to achieve this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AciYp0lUEBgQ"
      },
      "source": [
        "def validate_k_on_dataset(X_train, y_train, X_val, y_val):\n",
        "    '''\n",
        "    A function that finds the best K using a (validation) dataset.\n",
        "    '''\n",
        "    # Initialize the best accuracy and associated k\n",
        "    best_knn_acc = 0\n",
        "    best_k = 0\n",
        "    # In Python, range doesn't include the last element; this is the list [1,2,...10]\n",
        "    k_vec = list(range(1, 11))\n",
        "    # Loop through each k\n",
        "    for i in k_vec:\n",
        "        \n",
        "        ### ADD CODE HERE:\n",
        "        # Compute the accuracy on the validation set using the current k\n",
        "        ###\n",
        "        knn_acc = compute_accuracy_on_dataset(X_train, y_train, X_val, y_val, i)\n",
        "        # If this k is better, replace the current best accuracy and k\n",
        "        if knn_acc > best_knn_acc:\n",
        "            best_knn_acc = knn_acc\n",
        "            best_k = i\n",
        "            \n",
        "    return best_knn_acc, best_k"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2xGV6RJEBgR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a45cce7-c416-493b-9d92-3f4e2cb3b875"
      },
      "source": [
        "### ADD CODE HERE:\n",
        "# Call the above function and print the resulting accuracy and best k for the validation set\n",
        "###\n",
        "best_knn_acc, best_k = validate_k_on_dataset(xtrain, ytrain, xval, yval)\n",
        "print(\"Best accuracy on validation set was\", best_knn_acc, \"with k =\", best_k)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best accuracy on validation set was 0.9944444444444445 with k = 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "670flASdEBgR"
      },
      "source": [
        "#### 3.e. Merge the training and validation sets, and report the new test accuracy using the best `k`.\n",
        "Since we've already used the validation set to obtain the best `k`, we can now merge the training set and the validation set and recompute KNN on the test set with the best `k`. \n",
        "\n",
        "Make sure to merge the data points in the same order that you merge the labels!\n",
        "\n",
        "##### Merge the training and validation sets. *(Hint*: Use [np.vstack](https://numpy.org/doc/stable/reference/generated/numpy.vstack.html) and [np.concatenate](https://numpy.org/doc/stable/reference/generated/numpy.concatenate.html).)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjUcZKEsEBgR"
      },
      "source": [
        "import numpy as np \n",
        "\n",
        "### ADD CODE HERE:\n",
        "# Use np.vstack to stack X_train and X_val\n",
        "###\n",
        "xtrain_and_xval = np.vstack((xtrain, xval))\n",
        "### ADD CODE HERE:\n",
        "# Use np.concatenate to concatenate y_train and y_val\n",
        "###\n",
        "ytrain_and_yval = np.concatenate((ytrain, yval))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJNBbfdrEBgS"
      },
      "source": [
        "###### Now, recompute the accuracy on the test set using this merged dataset (instead of just the training set) and the best `k` value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwYKouhZEBgS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8acbe4c3-dabc-4c69-8cf4-b0b2929fbb77"
      },
      "source": [
        "### ADD CODE HERE:\n",
        "# Compute the accuracy on the test set using the merged train and validation set and the best k\n",
        "###\n",
        "knn_acc = compute_accuracy_on_dataset(xtrain_and_xval, ytrain_and_yval, xtest, ytest, best_k)\n",
        "print(\"KNN accuracy on test set using merged train and validation sets and best K value:\", knn_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNN accuracy on test set using merged train and validation sets and best K value: 0.9833333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIQe3e5UEBgT"
      },
      "source": [
        "### 4. Comparing Decision Trees and K-Nearest Neighbors on Raw Wine Data\n",
        "We're going to compare the performance of our KNN algorithm and the decision tree algorithm on a new dataset.\n",
        "\n",
        "The wine dataset is the result of a chemical analysis of wines grown in the same region in Italy by three different cultivators. There are 13 different measurements (features) taken for different constituents found in the three types of wine."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGuIFHe2EBgT"
      },
      "source": [
        "#### Import the wine dataset and view it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDYClJvtEBgU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "68530918-e330-47b6-f567-580d8c24a427"
      },
      "source": [
        "from sklearn.datasets import load_wine\n",
        "\n",
        "# Import the data into a pandas dataframe\n",
        "wine = load_wine()\n",
        "wine_df = pd.DataFrame(wine.data, columns = wine.feature_names)\n",
        "\n",
        "# Split data into features and labels\n",
        "X_w = wine.data\n",
        "y_w = wine.target\n",
        "\n",
        "# View the raw data\n",
        "wine_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113.0</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   alcohol  malic_acid   ash  ...   hue  od280/od315_of_diluted_wines  proline\n",
              "0    14.23        1.71  2.43  ...  1.04                          3.92   1065.0\n",
              "1    13.20        1.78  2.14  ...  1.05                          3.40   1050.0\n",
              "2    13.16        2.36  2.67  ...  1.03                          3.17   1185.0\n",
              "3    14.37        1.95  2.50  ...  0.86                          3.45   1480.0\n",
              "4    13.24        2.59  2.87  ...  1.04                          2.93    735.0\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NL0Xl_naEBgU"
      },
      "source": [
        "#### 4.a. Split the data into train, test and validation sets.\n",
        "\n",
        "Use a 60/20/20 split. Make sure to set `random_state=42` to shuffle the dataset in a consistent manner."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deEixnF3EBgU"
      },
      "source": [
        "### ADD CODE HERE:\n",
        "# Split the data into training, test, and validation sets, just like we did on HW 2\n",
        "# Make sure to set random_state=42!\n",
        "###\n",
        "x_wtrain, x_wtest, y_wtrain, y_wtest = train_test_split(X_w, y_w, random_state=42, train_size=.8) # -- Code Required --\n",
        "x_wtrain, x_wval, y_wtrain, y_wval = train_test_split(x_wtrain, y_wtrain, random_state=42, train_size=.75) # -- Code Required --"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlO0iMwwEBgV"
      },
      "source": [
        "#### 4.b. KNN: Find the best `k` and accuracy for this dataset.\n",
        "Use the same process as in question 3 to:\n",
        "\n",
        "##### 1. Validate `k`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQLtVjHZEBgV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66e801ff-6cda-44bb-beef-1ad15656577b"
      },
      "source": [
        "### ADD CODE HERE:\n",
        "# Call validate_k_on_dataset() and print the resulting accuracy and best k for the validation set\n",
        "###\n",
        "best_w_knn_acc, best_w_k = validate_k_on_dataset(x_wtrain, y_wtrain, x_wval, y_wval)\n",
        "print(\"Best accuracy on validation set was\", best_w_knn_acc, \"with k =\", best_w_k)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best accuracy on validation set was 0.8333333333333334 with k = 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPO-wsudEBgV"
      },
      "source": [
        "##### 2. Merge the training and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTmmr7ZrEBgW"
      },
      "source": [
        "### ADD CODE HERE:\n",
        "# Use np.vstack to stack X_train and X_val\n",
        "###\n",
        "x_wtrain_and_val = np.vstack((x_wtrain, x_wval))\n",
        "### ADD CODE HERE:\n",
        "# Use np.concatenate to concatenate y_train and y_val\n",
        "###\n",
        "y_wtrain_and_val = np.concatenate((y_wtrain, y_wval))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXdhKrTcEBgW"
      },
      "source": [
        "##### 3. Report the new accuracy on the test set; recompute KNN using the merged dataset and the best `k` value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfdenCfTEBgW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e2c2cef-9e19-4f98-aed5-706d262cb9e2"
      },
      "source": [
        "### ADD CODE HERE:\n",
        "# Compute the accuracy on the test set using the merged train and validation set and the best k\n",
        "###\n",
        "w_knn_acc = compute_accuracy_on_dataset(x_wtrain_and_val, y_wtrain_and_val, x_wtest, y_wtest, best_w_k)\n",
        "print(\"KNN accuracy on test set using merged train and validation sets and best K value:\", w_knn_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNN accuracy on test set using merged train and validation sets and best K value: 0.75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V85BjuwrEBgX"
      },
      "source": [
        "#### 4.c. Decision Trees: Use `sklearn`'s built-in decision tree on this dataset and report the accuracy.\n",
        "You can find the documentation for instantiating and fitting `sklearn`'s `DecisionTreeClassifier` [here](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html).\n",
        "\n",
        "You can find the documentation for using `metrics.accuracy_score` to compute the accuracy given predictions and true labels [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html).\n",
        "\n",
        "*Make sure to use the merged training and validation set to fit the decision tree (for a fair comparison to KNN)!*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_shKOma3EBgX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1c4515e-822a-4ad7-bf8e-de6d0b2f77f0"
      },
      "source": [
        "from sklearn import tree\n",
        "from sklearn import metrics\n",
        "\n",
        "### ADD CODE HERE:\n",
        "# Instantiate the decision tree.\n",
        "###\n",
        "clf = tree.DecisionTreeClassifier(random_state=0)\n",
        "\n",
        "### ADD CODE HERE:\n",
        "# Fit the tree with the merged training and validation set.\n",
        "###\n",
        "fitted = clf.fit(x_wtrain_and_val, y_wtrain_and_val)\n",
        "\n",
        "### ADD CODE HERE:\n",
        "# Use the tree to predict on the test set.\n",
        "###\n",
        "prediction = clf.predict(x_wtest)\n",
        "\n",
        "### ADD CODE HERE:\n",
        "# Use metrics.accuracy_score to get the accuracy of this decision tree on the test set.\n",
        "###\n",
        "tree_acc = metrics.accuracy_score(y_wtest, prediction)\n",
        "\n",
        "print(\"Decision tree accuracy on test set:\", tree_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decision tree accuracy on test set: 0.9444444444444444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Slr4S8TEBgY"
      },
      "source": [
        "#### 4.d. Explain the difference in performance between these two algorithms; why does one perform better than the other?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Y2QNN84EBgY"
      },
      "source": [
        "The decision tree has a higher accuracy than KNN for the wine data due to the number of features present (Curse of Dimensionality). As the feature space expands, and more dimensions of data are present, it becomes increasingly difficult to calculate accurate distance measurements between datapoints, causing KNN's accuracy to decrease, meaning it's harder to classify the data. In contrast, a decision tree is better able to handle the high feature count, and can still accurately label the data."
      ]
    }
  ]
}